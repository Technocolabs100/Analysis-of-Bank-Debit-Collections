{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anas1IA/Analysis-of-Bank-Debit-Collections/blob/main/iam_handwritten_forms_writer_identifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.013489,
          "end_time": "2021-01-20T05:33:45.270657",
          "exception": false,
          "start_time": "2021-01-20T05:33:45.257168",
          "status": "completed"
        },
        "tags": [],
        "id": "lK389VVfk65r"
      },
      "source": [
        "# A writer identifier implementation that uses randomly generated training and test data from the IAM dataset\n",
        "\n",
        "## Project Pipeline\n",
        "\n",
        "This project adopts the following machine learning pipeline:\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "## Preprocessing\n",
        "\n",
        "Input images are processed according to the chosen features extraction method, but whatever the chosen extraction method is, the image essentially goes through the same procedures. The preprocessing module simply crops the image to its useful content (i.e the handwritten text corpus) and returns a binarized version of the cropped image and a grayscale version depending on the type of the features extraction method.\n",
        "\n",
        "## Features Extraction\n",
        "\n",
        "The features extraction phase is inspired by [this paper](https://www.sciencedirect.com/science/article/abs/pii/S0045790617322401). Two similar methods are implemented for extracting features from raw images. The first is implemented as proposed in the paper where the image is segmented into words images which are then overlapped into a single image to represent the texture of a particular writer’s handwriting. Texture images are then segmented into texture blocks that are each represented as an input vector for the next phase using their local binary pattern histograms.\n",
        "\n",
        "The other feature extraction method works by simply feeding the model in the next phase raw segmented images (e.g sentences, words) of the cropped image. Despite being simple, this method takes much more time to execute than the overlapping method mentioned above as it takes an average execution time of 10 seconds per iteration while the overlapping method takes around 3.5 seconds per iteration, in addition to that, the overlapping method yields better accuracy by a slight yet accountable margin making matter disadvantageous for the lines method.\n",
        "\n",
        "## Model Generation\n",
        "\n",
        "The output of the previous step is feed to a model generator function that’s responsible for both generating and training a model. You can either choose a support vector machine classifier or a neural network classifier to classify test images. Both yield exceptional results when running on 1000 random samples, the neural network classifier has a slight edge over the SVM classifier in terms of accuracy as it achieves 98.8% accuracy compared to 98.2%. On the other side of the coin, the SVM classifier is faster than the neural network one having an average iteration runtime of 3.4 seconds instead of 14.7 seconds but keep in mind that neural network classifiers performance can be improved by GPU acceleration which indeed reduced the neural network classifier average iteration runtime from 14.7 seconds to 8.7 seconds.\n",
        "\n",
        "## Training and Test Samples Generation\n",
        "\n",
        "At each epoch, 3 random writers directories are chosen from the dataset where 2 random images are read from each writer's directory and an extra image to be used for testing is randomly chosen from the three writers' directories. This process ends up with 7 labelled images, 6 for training (2 for each writer) and 1 for testing."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsDq6jIglAp2",
        "outputId": "1d4a41db-0848-45be-d0c8-15a6475452bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/DATACLEAN\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7R443gHllmm",
        "outputId": "c522885a-4cd4-4c8e-ee78-8fcd8675ae73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0001  0027  0081  0169\t0190  0210  0232  0252\t0324  0399  0485  0550\t0592  0895  0941  1101\n",
            "0002  0028  0083  0170\t0191  0211  0233  0254\t0327  0400  0507  0556\t0598  0901  0944  1105\n",
            "0003  0029  0084  0171\t0192  0212  0234  0255\t0358  0403  0510  0558\t0599  0907  0945  1117\n",
            "0004  0041  0095  0172\t0193  0213  0235  0256\t0363  0405  0519  0560\t0600  0909  0946  1120\n",
            "0005  0042  0096  0173\t0194  0214  0236  0262\t0368  0408  0520  0561\t0602  0918  0948  1121\n",
            "0006  0047  0097  0175\t0195  0215  0237  0263\t0369  0410  0522  0562\t0603  0920  0950  1122\n",
            "0012  0050  0098  0176\t0196  0216  0238  0265\t0374  0411  0524  0564\t0604  0921  0952  1124\n",
            "0013  0052  0152  0177\t0197  0217  0239  0285\t0383  0412  0525  0565\t0606  0922  0953  1130\n",
            "0014  0053  0153  0178\t0198  0218  0240  0286\t0384  0413  0527  0566\t0607  0923  0956\n",
            "0015  0057  0155  0179\t0199  0219  0241  0287\t0386  0418  0528  0567\t0609  0925  0957\n",
            "0016  0058  0156  0180\t0200  0220  0242  0288\t0387  0425  0530  0568\t0612  0926  0960\n",
            "0017  0059  0157  0181\t0201  0221  0243  0289\t0388  0429  0534  0570\t0704  0927  0962\n",
            "0018  0073  0161  0182\t0202  0222  0244  0290\t0390  0430  0535  0571\t0705  0928  0963\n",
            "0020  0074  0162  0183\t0203  0223  0245  0291\t0391  0431  0538  0573\t0706  0932  0964\n",
            "0021  0075  0163  0184\t0204  0224  0246  0299\t0392  0432  0539  0575\t0707  0934  0965\n",
            "0022  0076  0164  0185\t0205  0227  0247  0309\t0393  0476  0540  0577\t0709  0935  0966\n",
            "0023  0077  0165  0186\t0206  0228  0248  0311\t0394  0477  0541  0578\t0710  0936  0968\n",
            "0024  0078  0166  0187\t0207  0229  0249  0312\t0395  0479  0547  0580\t0717  0937  0972\n",
            "0025  0079  0167  0188\t0208  0230  0250  0313\t0396  0481  0548  0582\t0718  0938  0976\n",
            "0026  0080  0168  0189\t0209  0231  0251  0322\t0398  0482  0549  0585\t0894  0939  0992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-20T05:33:45.303563Z",
          "iopub.status.busy": "2021-01-20T05:33:45.302760Z",
          "iopub.status.idle": "2021-01-20T05:33:48.945408Z",
          "shell.execute_reply": "2021-01-20T05:33:48.944382Z"
        },
        "papermill": {
          "duration": 3.662741,
          "end_time": "2021-01-20T05:33:48.945546",
          "exception": false,
          "start_time": "2021-01-20T05:33:45.282805",
          "status": "completed"
        },
        "tags": [],
        "id": "sQpHPww5k65y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "from os import walk\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from skimage.feature import local_binary_pattern\n",
        "from skimage.measure import find_contours\n",
        "from skimage.morphology import binary_dilation\n",
        "from sklearn.svm import SVC\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import TensorDataset\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-20T05:33:49.366778Z",
          "iopub.status.busy": "2021-01-20T05:33:49.365557Z",
          "iopub.status.idle": "2021-01-20T05:33:49.371882Z",
          "shell.execute_reply": "2021-01-20T05:33:49.374052Z"
        },
        "papermill": {
          "duration": 0.416219,
          "end_time": "2021-01-20T05:33:49.374370",
          "exception": false,
          "start_time": "2021-01-20T05:33:48.958151",
          "status": "completed"
        },
        "tags": [],
        "id": "8kYVNEwDk651"
      },
      "outputs": [],
      "source": [
        "# Parameters and constants\n",
        "AVAILABLE_WRITERS = 308\n",
        "RESULTS_FILE = 'results.txt'\n",
        "TIME_FILE = 'time.txt'\n",
        "OVERLAPPING_METHOD = 0\n",
        "LINES_METHOD = 1\n",
        "SUPPORT_VECTOR_CLASSIFIER = 0\n",
        "NEURAL_NETWORK_CLASSIFIER = 1\n",
        "HISTOGRAM_BINS = 256\n",
        "NN_LEARNING_RATE = 0.003\n",
        "NN_WEIGHT_DECAY = 0.01\n",
        "NN_DROPOUT = 0.25\n",
        "NN_EPOCHS = 200\n",
        "NN_BATCH_SIZE = 16\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-20T05:33:49.434180Z",
          "iopub.status.busy": "2021-01-20T05:33:49.433346Z",
          "iopub.status.idle": "2021-01-20T05:33:49.441421Z",
          "shell.execute_reply": "2021-01-20T05:33:49.440691Z"
        },
        "papermill": {
          "duration": 0.037805,
          "end_time": "2021-01-20T05:33:49.441567",
          "exception": false,
          "start_time": "2021-01-20T05:33:49.403762",
          "status": "completed"
        },
        "tags": [],
        "id": "hCTTb52pk652"
      },
      "outputs": [],
      "source": [
        "def show_images(images, titles=None):\n",
        "    n_ims = len(images)\n",
        "    if titles is None:\n",
        "        titles = ['(%d)' % i for i in range(1, n_ims + 1)]\n",
        "    fig = plt.figure()\n",
        "    n = 1\n",
        "    for image, title in zip(images, titles):\n",
        "        a = fig.add_subplot(1, n_ims, n)\n",
        "        if image.ndim == 2:\n",
        "            plt.gray()\n",
        "        plt.imshow(image)\n",
        "        a.set_title(title)\n",
        "        n += 1\n",
        "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-20T05:33:49.504840Z",
          "iopub.status.busy": "2021-01-20T05:33:49.504016Z",
          "iopub.status.idle": "2021-01-20T05:33:49.507509Z",
          "shell.execute_reply": "2021-01-20T05:33:49.508495Z"
        },
        "papermill": {
          "duration": 0.044216,
          "end_time": "2021-01-20T05:33:49.508652",
          "exception": false,
          "start_time": "2021-01-20T05:33:49.464436",
          "status": "completed"
        },
        "tags": [],
        "id": "-5EkH1kek653"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(img, feature_extraction_method=OVERLAPPING_METHOD):\n",
        "    if feature_extraction_method == OVERLAPPING_METHOD:\n",
        "        img_copy = img.copy()\n",
        "        if len(img.shape) > 2:\n",
        "            img_copy = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n",
        "        img_copy = cv2.medianBlur(img_copy, 5)\n",
        "        img_copy = cv2.threshold(img_copy, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "        min_vertical, max_vertical = get_corpus_boundaries(img_copy)\n",
        "        img_copy = img_copy[min_vertical:max_vertical]\n",
        "        return img_copy\n",
        "\n",
        "    if feature_extraction_method == LINES_METHOD:\n",
        "        img_copy = img.copy()\n",
        "        if len(img.shape) > 2:\n",
        "            grayscale_img = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n",
        "        else:\n",
        "            grayscale_img = img.copy()\n",
        "        img_copy = cv2.threshold(grayscale_img, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "        min_vertical, max_vertical = get_corpus_boundaries(img_copy)\n",
        "        img_copy = img_copy[min_vertical:max_vertical]\n",
        "        grayscale_img = grayscale_img[min_vertical:max_vertical]\n",
        "        filter_kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
        "        img_copy_sharpened = cv2.filter2D(img_copy, -1, filter_kernel)\n",
        "        return img_copy_sharpened, grayscale_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-20T05:33:49.555155Z",
          "iopub.status.busy": "2021-01-20T05:33:49.554355Z",
          "iopub.status.idle": "2021-01-20T05:33:49.560164Z",
          "shell.execute_reply": "2021-01-20T05:33:49.561165Z"
        },
        "papermill": {
          "duration": 0.03495,
          "end_time": "2021-01-20T05:33:49.561318",
          "exception": false,
          "start_time": "2021-01-20T05:33:49.526368",
          "status": "completed"
        },
        "tags": [],
        "id": "5hgzpAsCk654"
      },
      "outputs": [],
      "source": [
        "def get_corpus_boundaries(img):\n",
        "    crop = []\n",
        "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (100, 1))\n",
        "    detect_horizontal = cv2.morphologyEx(img, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)\n",
        "    contours = cv2.findContours(detect_horizontal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "    prev = -1\n",
        "    for i, c in enumerate(contours):\n",
        "        if np.abs(prev - int(c[0][0][1])) > 800 or prev == -1:\n",
        "            crop.append(int(c[0][0][1]))\n",
        "            prev = int(c[0][0][1])\n",
        "    crop.sort()\n",
        "    max_vertical = crop[1] - 20\n",
        "    min_vertical = crop[0] + 20\n",
        "    return min_vertical, max_vertical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-20T05:33:49.608439Z",
          "iopub.status.busy": "2021-01-20T05:33:49.607593Z",
          "iopub.status.idle": "2021-01-20T05:33:49.618672Z",
          "shell.execute_reply": "2021-01-20T05:33:49.619697Z"
        },
        "papermill": {
          "duration": 0.04078,
          "end_time": "2021-01-20T05:33:49.619847",
          "exception": false,
          "start_time": "2021-01-20T05:33:49.579067",
          "status": "completed"
        },
        "tags": [],
        "id": "dpnUHqPik654"
      },
      "outputs": [],
      "source": [
        "def segment_image(img, num, grayscale_img=None):\n",
        "    if grayscale_img is not None:\n",
        "        grayscale_images = []\n",
        "        img_copy = np.copy(img)\n",
        "        kernel = np.ones((1, num))\n",
        "        img_copy = binary_dilation(img_copy, kernel)\n",
        "        bounding_boxes = find_contours(img_copy, 0.8)\n",
        "        for box in bounding_boxes:\n",
        "            x_min = int(np.min(box[:, 1]))\n",
        "            x_max = int(np.max(box[:, 1]))\n",
        "            y_min = int(np.min(box[:, 0]))\n",
        "            y_max = int(np.max(box[:, 0]))\n",
        "            if (y_max - y_min) > 50 and (x_max - x_min) > 50:\n",
        "                grayscale_images.append(grayscale_img[y_min:y_max, x_min:x_max])\n",
        "        return grayscale_images\n",
        "    images = []\n",
        "    img_copy = np.copy(img)\n",
        "    kernel = np.ones((1, num))\n",
        "    img_copy = binary_dilation(img_copy, kernel)\n",
        "    bounding_boxes = find_contours(img_copy, 0.8)\n",
        "    for box in bounding_boxes:\n",
        "        x_min = int(np.min(box[:, 1]))\n",
        "        x_max = int(np.max(box[:, 1]))\n",
        "        y_min = int(np.min(box[:, 0]))\n",
        "        y_max = int(np.max(box[:, 0]))\n",
        "        if (y_max - y_min) > 10 and (x_max - x_min) > 10:\n",
        "            images.append(img[y_min:y_max, x_min:x_max])\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-20T05:33:49.669297Z",
          "iopub.status.busy": "2021-01-20T05:33:49.668487Z",
          "iopub.status.idle": "2021-01-20T05:33:49.672403Z",
          "shell.execute_reply": "2021-01-20T05:33:49.673383Z"
        },
        "papermill": {
          "duration": 0.03598,
          "end_time": "2021-01-20T05:33:49.673527",
          "exception": false,
          "start_time": "2021-01-20T05:33:49.637547",
          "status": "completed"
        },
        "tags": [],
        "id": "xMnRhdU4k655"
      },
      "outputs": [],
      "source": [
        "def overlap_words(words, avg_height):\n",
        "    overlapped_img = np.zeros((3600, 320))\n",
        "    index_i = 0\n",
        "    index_j = 0\n",
        "    max_height = 0\n",
        "    for word in words:\n",
        "        if word.shape[1] + index_j > overlapped_img.shape[1]:\n",
        "            max_height = 0\n",
        "            index_j = 0\n",
        "            index_i += int(avg_height // 2)\n",
        "        if word.shape[1] < overlapped_img.shape[1] and word.shape[0] < overlapped_img.shape[0]:\n",
        "            indices = np.copy(overlapped_img[index_i:index_i + word.shape[0], index_j:index_j + word.shape[1]])\n",
        "            indices = np.maximum(indices, word)\n",
        "            overlapped_img[index_i:index_i + word.shape[0], index_j:index_j + word.shape[1]] = indices\n",
        "            index_j += word.shape[1]\n",
        "            if max_height < word.shape[0]:\n",
        "                max_height = word.shape[0]\n",
        "    overlapped_img = overlapped_img[:index_i + int(avg_height // 2), :]\n",
        "    return overlapped_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-20T05:33:49.732671Z",
          "iopub.status.busy": "2021-01-20T05:33:49.731861Z",
          "iopub.status.idle": "2021-01-20T05:33:49.743014Z",
          "shell.execute_reply": "2021-01-20T05:33:49.743637Z"
        },
        "papermill": {
          "duration": 0.052746,
          "end_time": "2021-01-20T05:33:49.743784",
          "exception": false,
          "start_time": "2021-01-20T05:33:49.691038",
          "status": "completed"
        },
        "tags": [],
        "id": "o0nD0UH5k655"
      },
      "outputs": [],
      "source": [
        "def get_textures(image):\n",
        "    index_i = 0\n",
        "    index_j = 0\n",
        "    texture_size = 100\n",
        "    textures = []\n",
        "    while index_i + texture_size < image.shape[0]:\n",
        "        if index_j + texture_size > image.shape[1]:\n",
        "            index_j = 0\n",
        "            index_i += texture_size\n",
        "        textures.append(np.copy(image[index_i: index_i + texture_size, index_j: index_j + texture_size]))\n",
        "        index_j += texture_size\n",
        "    return textures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-20T05:33:49.788902Z",
          "iopub.status.busy": "2021-01-20T05:33:49.788057Z",
          "iopub.status.idle": "2021-01-20T05:33:49.809688Z",
          "shell.execute_reply": "2021-01-20T05:33:49.810355Z"
        },
        "papermill": {
          "duration": 0.048922,
          "end_time": "2021-01-20T05:33:49.810511",
          "exception": false,
          "start_time": "2021-01-20T05:33:49.761589",
          "status": "completed"
        },
        "tags": [],
        "id": "uAJkRGlfk656"
      },
      "outputs": [],
      "source": [
        "def model_generator(features, labels, feature_extraction_method=OVERLAPPING_METHOD,\n",
        "                    classifier_type=SUPPORT_VECTOR_CLASSIFIER):\n",
        "    histograms = []\n",
        "\n",
        "    if feature_extraction_method == OVERLAPPING_METHOD:\n",
        "        for texture_array in features:\n",
        "            for texture in texture_array:\n",
        "                lbp = local_binary_pattern(texture, 8, 3, 'default')\n",
        "                histogram, _ = np.histogram(lbp, density=False, bins=HISTOGRAM_BINS, range=(0, HISTOGRAM_BINS))\n",
        "                histograms.append(histogram)\n",
        "\n",
        "    elif feature_extraction_method == LINES_METHOD:\n",
        "        for line in features:\n",
        "            lbp = local_binary_pattern(line, 8, 3, 'default')\n",
        "            histogram, _ = np.histogram(lbp, density=False, bins=HISTOGRAM_BINS, range=(0, HISTOGRAM_BINS))\n",
        "            histograms.append(histogram)\n",
        "\n",
        "    if classifier_type == SUPPORT_VECTOR_CLASSIFIER:\n",
        "        model = SVC(kernel='linear')\n",
        "        model.fit(histograms, labels)\n",
        "        return model\n",
        "\n",
        "    if classifier_type == NEURAL_NETWORK_CLASSIFIER:\n",
        "        model = nn.Sequential(nn.Linear(HISTOGRAM_BINS, 128),\n",
        "                              nn.ReLU(),\n",
        "                              nn.Dropout(p=NN_DROPOUT),\n",
        "                              nn.Linear(128, 64),\n",
        "                              nn.ReLU(),\n",
        "                              nn.Dropout(p=NN_DROPOUT),\n",
        "                              nn.Linear(64, 3))\n",
        "        model.to(DEVICE)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adamax(model.parameters(), lr=NN_LEARNING_RATE, weight_decay=NN_WEIGHT_DECAY)\n",
        "        inputs = torch.Tensor(histograms)\n",
        "        labels = torch.tensor(labels, dtype=torch.long) - 1\n",
        "        dataset = TensorDataset(inputs, labels)\n",
        "        train_loader = torch.utils.data.DataLoader(dataset, batch_size=NN_BATCH_SIZE, shuffle=True)\n",
        "        for epoch in range(NN_EPOCHS):\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "                output = model(inputs)\n",
        "                loss = criterion(output, labels)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-20T05:33:49.859272Z",
          "iopub.status.busy": "2021-01-20T05:33:49.858405Z",
          "iopub.status.idle": "2021-01-20T05:33:49.880866Z",
          "shell.execute_reply": "2021-01-20T05:33:49.880048Z"
        },
        "papermill": {
          "duration": 0.051448,
          "end_time": "2021-01-20T05:33:49.880991",
          "exception": false,
          "start_time": "2021-01-20T05:33:49.829543",
          "status": "completed"
        },
        "tags": [],
        "id": "JUCZlfDEk657"
      },
      "outputs": [],
      "source": [
        "def predict(model, test_image, feature_extraction_method=OVERLAPPING_METHOD, classifier_type=SUPPORT_VECTOR_CLASSIFIER):\n",
        "    if feature_extraction_method == OVERLAPPING_METHOD:\n",
        "        img = preprocess_image(test_image)\n",
        "        words = segment_image(img, 3)\n",
        "        avg_height = 0\n",
        "        for word in words:\n",
        "            avg_height += word.shape[0] / len(words)\n",
        "        overlapped_img = overlap_words(words, avg_height)\n",
        "        textures = get_textures(overlapped_img)\n",
        "        prediction = np.zeros(4)\n",
        "        for texture in textures:\n",
        "            lbp = local_binary_pattern(texture, 8, 3, 'default')\n",
        "            histogram, _ = np.histogram(lbp, density=False, bins=HISTOGRAM_BINS, range=(0, HISTOGRAM_BINS))\n",
        "            if classifier_type == SUPPORT_VECTOR_CLASSIFIER:\n",
        "                prediction[model.predict([histogram])] += 1\n",
        "            if classifier_type == NEURAL_NETWORK_CLASSIFIER:\n",
        "                with torch.no_grad():\n",
        "                    model.eval()\n",
        "                    histogram = torch.Tensor(histogram)\n",
        "                    probabilities = F.softmax(model.forward(histogram), dim=0)\n",
        "                    _, top_class = probabilities.topk(1)\n",
        "                    prediction[top_class + 1] += 1\n",
        "        return np.argmax(prediction)\n",
        "\n",
        "    if feature_extraction_method == LINES_METHOD:\n",
        "        img, grayscale_img = preprocess_image(test_image, feature_extraction_method)\n",
        "        grayscale_lines = segment_image(img, 100, grayscale_img)\n",
        "        prediction = np.zeros(4)\n",
        "        for line in grayscale_lines:\n",
        "            lbp = local_binary_pattern(line, 8, 3, 'default')\n",
        "            histogram, _ = np.histogram(lbp, density=False, bins=HISTOGRAM_BINS, range=(0, HISTOGRAM_BINS))\n",
        "            if classifier_type == SUPPORT_VECTOR_CLASSIFIER:\n",
        "                prediction[model.predict([histogram])] += 1\n",
        "            if classifier_type == NEURAL_NETWORK_CLASSIFIER:\n",
        "                with torch.no_grad():\n",
        "                    model.eval()\n",
        "                    histogram = torch.Tensor(histogram)\n",
        "                    probabilities = F.softmax(model.forward(histogram), dim=0)\n",
        "                    _, top_class = probabilities.topk(1)\n",
        "                    prediction[top_class + 1] += 1\n",
        "        return np.argmax(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-20T05:33:49.942044Z",
          "iopub.status.busy": "2021-01-20T05:33:49.941167Z",
          "iopub.status.idle": "2021-01-20T05:33:49.957886Z",
          "shell.execute_reply": "2021-01-20T05:33:49.957259Z"
        },
        "papermill": {
          "duration": 0.054027,
          "end_time": "2021-01-20T05:33:49.958001",
          "exception": false,
          "start_time": "2021-01-20T05:33:49.903974",
          "status": "completed"
        },
        "tags": [],
        "id": "dCV7B04Qk657"
      },
      "outputs": [],
      "source": [
        "def read_random_images(root):\n",
        "    images = []\n",
        "    labels = []\n",
        "    test_images = []\n",
        "    test_labels = []\n",
        "    for i in range(3):\n",
        "        found_images = False\n",
        "        while not found_images:\n",
        "            images_path = root\n",
        "            random_writer = random.randrange(AVAILABLE_WRITERS)\n",
        "            if random_writer < 10:\n",
        "                random_writer = \"00\" + str(random_writer)\n",
        "            elif random_writer < 100:\n",
        "                random_writer = \"0\" + str(random_writer)\n",
        "            images_path = os.path.join(images_path, str(random_writer))\n",
        "            if not os.path.isdir(images_path):\n",
        "                continue\n",
        "            _, _, filenames = next(walk(images_path))\n",
        "            if len(filenames) <= 2 and i == 2 and len(test_images) == 0:\n",
        "                continue\n",
        "            if len(filenames) >= 2:\n",
        "                found_images = True\n",
        "                chosen_filenames = []\n",
        "                for j in range(2):\n",
        "                    random_filename = random.choice(filenames)\n",
        "                    while random_filename in chosen_filenames:\n",
        "                        random_filename = random.choice(filenames)\n",
        "                    chosen_filenames.append(random_filename)\n",
        "                    images.append(cv2.imread(os.path.join(images_path, random_filename)))\n",
        "                    labels.append(i + 1)\n",
        "                if len(filenames) >= 3:\n",
        "                    random_filename = random.choice(filenames)\n",
        "                    while random_filename in chosen_filenames:\n",
        "                        random_filename = random.choice(filenames)\n",
        "                    chosen_filenames.append(random_filename)\n",
        "                    test_images.append(cv2.imread(os.path.join(images_path, random_filename)))\n",
        "                    test_labels.append(i + 1)\n",
        "    test_choice = random.randint(0, len(test_images) - 1)\n",
        "    test_image = test_images[test_choice]\n",
        "    test_label = test_labels[test_choice]\n",
        "    return images, labels, test_image, test_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-20T05:33:49.995752Z",
          "iopub.status.busy": "2021-01-20T05:33:49.994942Z",
          "iopub.status.idle": "2021-01-20T05:33:49.998390Z",
          "shell.execute_reply": "2021-01-20T05:33:49.998826Z"
        },
        "papermill": {
          "duration": 0.027293,
          "end_time": "2021-01-20T05:33:49.998943",
          "exception": false,
          "start_time": "2021-01-20T05:33:49.971650",
          "status": "completed"
        },
        "tags": [],
        "id": "hiyhvZp9k658"
      },
      "outputs": [],
      "source": [
        "def extract_features(images, labels, feature_extraction_method=OVERLAPPING_METHOD):\n",
        "    if feature_extraction_method == LINES_METHOD:\n",
        "        lines_labels = []\n",
        "        lines = []\n",
        "        for image, label in zip(images, labels):\n",
        "            image, grayscale_image = preprocess_image(image, feature_extraction_method)\n",
        "            grayscale_lines = segment_image(image, 100, grayscale_image)\n",
        "            for line in grayscale_lines:\n",
        "                lines.append(line)\n",
        "                lines_labels.append(label)\n",
        "        return lines, lines_labels\n",
        "\n",
        "    if feature_extraction_method == OVERLAPPING_METHOD:\n",
        "        textures = []\n",
        "        textures_labels = []\n",
        "        for image, label in zip(images, labels):\n",
        "            image = preprocess_image(image)\n",
        "            words = segment_image(image, 3)\n",
        "            avg_height = 0\n",
        "            for word in words:\n",
        "                avg_height += word.shape[0] / len(words)\n",
        "            overlapped_img = overlap_words(words, avg_height)\n",
        "            new_textures = get_textures(overlapped_img)\n",
        "            textures.append(new_textures)\n",
        "            for j in range(len(new_textures)):\n",
        "                textures_labels.append(label)\n",
        "        return textures, textures_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-20T05:33:50.034879Z",
          "iopub.status.busy": "2021-01-20T05:33:50.034241Z",
          "iopub.status.idle": "2021-01-20T05:42:40.539256Z",
          "shell.execute_reply": "2021-01-20T05:42:40.539853Z"
        },
        "papermill": {
          "duration": 530.528393,
          "end_time": "2021-01-20T05:42:40.540040",
          "exception": false,
          "start_time": "2021-01-20T05:33:50.011647",
          "status": "completed"
        },
        "tags": [],
        "id": "7gDqDCkgk658"
      },
      "outputs": [],
      "source": [
        "epochs = 1\n",
        "root=\"/content/drive/My Drive/DATACLEAN\"\n",
        "feature_extraction_method=OVERLAPPING_METHOD\n",
        "classifier_type=SUPPORT_VECTOR_CLASSIFIER\n",
        "correct_predictions = 0\n",
        "total_execution_time = 0\n",
        "for epoch in range(epochs):\n",
        "    images, labels, test_image, test_label = read_random_images(root)\n",
        "    start_time = time.time()\n",
        "    features, features_labels = extract_features(images, labels, feature_extraction_method)\n",
        "    model = model_generator(features, features_labels, feature_extraction_method, classifier_type)\n",
        "    prediction = predict(model, test_image, feature_extraction_method, classifier_type)\n",
        "    execution_time = time.time() - start_time\n",
        "    total_execution_time += execution_time\n",
        "    if prediction == test_label:\n",
        "        correct_predictions += 1\n",
        "    print(\"Epoch #{} | Execution time {} seconds | Model accuracy {}\".format(epoch + 1, round(execution_time, 2), round((correct_predictions / (epoch + 1)) * 100, 2)))\n",
        "print(\"Model accuracy = {}% using {} sample tests.\".format((correct_predictions / epochs) * 100, epochs))\n",
        "print(\"Total execution time = {} using {} sample tests.\".format(round(total_execution_time, 2), epochs))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "papermill": {
      "duration": 540.971571,
      "end_time": "2021-01-20T05:42:41.656947",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-01-20T05:33:40.685376",
      "version": "2.1.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}