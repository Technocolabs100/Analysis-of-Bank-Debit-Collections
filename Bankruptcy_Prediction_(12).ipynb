{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anas1IA/Analysis-of-Bank-Debit-Collections/blob/main/Bankruptcy_Prediction_(12).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ox9mk8STK1kE",
        "outputId": "db1fa68d-6d2b-447a-9043-789290950493"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKjmTiQxIYth"
      },
      "source": [
        "## Contents  \n",
        "<ol>\n",
        "    <b><li>Importing libraries</li></b>\n",
        "    <li><b>Importing and organizing the data</b>\n",
        "        <ol>\n",
        "            <li>Convert the columns types for the features to float</li>\n",
        "            <li>Convert the class label types to int</li>\n",
        "        </ol>\n",
        "    </li>\n",
        "    <li><b>Data Analysis and Preprocessing</b>\n",
        "        <ol>\n",
        "            <li>Missing Data Analysis\n",
        "                <ol>\n",
        "                    <li>Generate Sparsity Matrix for the missing data</li>\n",
        "                    <li>Generate Heat Map for the missing data</li>\n",
        "                </ol>\n",
        "            </li>\n",
        "            <li>Data Imputation\n",
        "                <ol>\n",
        "                    <li>Mean Imputation</li>\n",
        "                    <li>K-NN</li>\n",
        "                    <li>EM</li>\n",
        "                    <li>MICE</li>\n",
        "                </ol>\n",
        "            </li>\n",
        "            <li>Dealing with imbalanced data\n",
        "                <ol>\n",
        "                    <li>Oversampling with SMOTE</li>\n",
        "                </ol>\n",
        "            </li>\n",
        "        </ol>\n",
        "    </li>\n",
        "    <li><b>Data Modeling</b>\n",
        "        <ol>\n",
        "            <li>K-Fold Cross validation</li>\n",
        "            <li>Models\n",
        "                <ol>\n",
        "                    <li>Gaussian Naive Bayes classifier</li>\n",
        "                    <li>Logistic Regression classifier</li>\n",
        "                    <li>Decision Tree classifier</li>\n",
        "                    <li>Random Forest classifier</li>\n",
        "                    <li>Extreme Gradient Boosting classifier</li>\n",
        "                    <li>Balanced Bagging classifier</li>\n",
        "                </ol>\n",
        "            </li>\n",
        "        </ol>\n",
        "    </li>\n",
        "    <li><b>Model Analysis</b>\n",
        "        <ol>\n",
        "            <li>Model ranking</li>\n",
        "            <li>Balanced Bagging: Effect of varying number of estimators on the accuracy scores on different datasets</li>\n",
        "            <li>Balanced Bagging: Plotting effect of number of estimators on Accuracy</li>\n",
        "        </ol>\n",
        "    </li>\n",
        "    <li><b>References</b></li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIpsir42IYti"
      },
      "source": [
        "## 1. Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fancyimpute\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBXULgUWKMng",
        "outputId": "4764edc3-5b5c-4bee-bba6-921cf004c504"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fancyimpute\n",
            "  Downloading fancyimpute-0.7.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting knnimpute>=0.1.0 (from fancyimpute)\n",
            "  Downloading knnimpute-0.1.0.tar.gz (8.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.2.2)\n",
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.3.2)\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.3.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (7.4.1)\n",
            "Collecting nose (from fancyimpute)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.11.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (3.2.0)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (0.6.2.post8)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (2.0.12)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (3.2.3)\n",
            "Requirement already satisfied: setuptools>65.5.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (67.7.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (23.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (1.1.3)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (2.0.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.4.1->cvxpy->fancyimpute) (0.1.7.post0)\n",
            "Building wheels for collected packages: fancyimpute, knnimpute\n",
            "  Building wheel for fancyimpute (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fancyimpute: filename=fancyimpute-0.7.0-py3-none-any.whl size=29880 sha256=22cebc48214b860e467b53a383141070a1ae7b6fe8cf9c8d7bf078d5bebb9898\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/0c/d3/ee82d1fbdcc0858d96434af108608d01703505d453720c84ed\n",
            "  Building wheel for knnimpute (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knnimpute: filename=knnimpute-0.1.0-py3-none-any.whl size=11329 sha256=2904c37876a5caadd30d08202cfc9b91ea56915c5b26d3a4790262c9371a56a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/06/a5/45a724630562413c374e29c08732411d496092408b3a7bf754\n",
            "Successfully built fancyimpute knnimpute\n",
            "Installing collected packages: nose, knnimpute, fancyimpute\n",
            "Successfully installed fancyimpute-0.7.0 knnimpute-0.1.0 nose-1.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2L7Ni288IYti"
      },
      "outputs": [],
      "source": [
        "# To supress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# Basic Libraries for Data organization, Statistical operations and Plotting\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "# For loading .arff files\n",
        "from scipy.io import arff\n",
        "# To analyze the type of missing data\n",
        "import missingno as msno\n",
        "# Library for performing k-NN and MICE imputations\n",
        "import fancyimpute\n",
        "# Library to perform Expectation-Maximization (EM) imputation\n",
        "from sklearn.impute import SimpleImputer\n",
        "# To perform mean imputation\n",
        "\n",
        "#To perform kFold Cross Validation\n",
        "from sklearn.model_selection import KFold\n",
        "# Formatted counter of class labels\n",
        "from collections import Counter\n",
        "# Ordered Dictionary\n",
        "from collections import OrderedDict\n",
        "# Library imbalanced-learn to deal with the data imbalance. To use SMOTE oversampling\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Impoting classification models\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.ensemble import BalancedBaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "import random\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import precision_recall_curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6stet8MzIYtk"
      },
      "source": [
        "## 2. Importing and organizing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSR3miKiIYtk"
      },
      "source": [
        "<b>Dataset Link:</b>The Dataset can be found at [Polish bankruptcy dataset](https://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZtpIRC3IYtl"
      },
      "source": [
        "There are a total of **5 .arff data files** with the names **`1year`, `2year`, `3year`, `4year`, `5year`**.   \n",
        "Load the .arff files and convert them into pandas dataframes using the `load_dataframes` function.   \n",
        "Give them new columns headers using the function `set_new_headers`. The column labels for the features are like `X1`, `X2`, ... , `X64`. The class label is `Y`.   \n",
        "Print the first 5 rows of a dataframe, to see how the data looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "O8CVY-suIYtl",
        "outputId": "0896d223-9e32-483c-f9d5-c657fe547592"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-96f57b2c506e>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m############################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# dataframes is the list of pandas dataframes for the 5 year datafiles.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdataframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Set the new headers for the dataframes. The new headers will have the renamed set of feature (X1 to X64)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-96f57b2c506e>\u001b[0m in \u001b[0;36mload_dataframes\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Loads the 5 raw .arff files into pandas dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dataframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_i_year\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata_i_year\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mload_arff_raw_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m############################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-96f57b2c506e>\u001b[0m in \u001b[0;36mload_arff_raw_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_arff_raw_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadarff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'year.arff'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m############################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-96f57b2c506e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_arff_raw_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadarff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'year.arff'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m############################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/io/arff/_arffread.py\u001b[0m in \u001b[0;36mloadarff\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0mofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m         \u001b[0mofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_loadarff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mofile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/1year.arff'"
          ]
        }
      ],
      "source": [
        "############################################################\n",
        "# Loads the 5 raw .arff files into a list\n",
        "def load_arff_raw_data():\n",
        "    N=5\n",
        "    return [arff.loadarff('data/' + str(i+1) + 'year.arff') for i in rang\n",
        "\n",
        "############################################################\n",
        "# Loads the 5 raw .arff files into pandas dataframes\n",
        "def load_dataframes():\n",
        "    return [pd.DataFrame(data_i_year[0]) for data_i_year in load_arff_raw_data()]\n",
        "\n",
        "############################################################\n",
        "# Set the column headers from X1 ... X64 and the class label as Y, for all the 5 dataframes.\n",
        "def set_new_headers(dataframes):\n",
        "    cols = ['X' + str(i+1) for i in range(len(dataframes[0].columns)-1)]\n",
        "    cols.append('Y')\n",
        "    for df in dataframes:\n",
        "        df.columns = cols\n",
        "\n",
        "############################################################\n",
        "# dataframes is the list of pandas dataframes for the 5 year datafiles.\n",
        "dataframes = load_dataframes()\n",
        "\n",
        "# Set the new headers for the dataframes. The new headers will have the renamed set of feature (X1 to X64)\n",
        "set_new_headers(dataframes)\n",
        "\n",
        "# print the first 5 rows of a dataset 'year1'\n",
        "dataframes[0].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAuJPXmRIYtm"
      },
      "source": [
        "#### 2.A Convert the columns types for the features to float\n",
        "The numeric data shown in the dataframe above is infact a python object. Let us convert all the numberic features for all the dataframes into float to maintain consistency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4BCYS35IYtm"
      },
      "outputs": [],
      "source": [
        "# Convert the dtypes of all the columns (other than the class label columns) to float.\n",
        "def convert_columns_type_float(dfs):\n",
        "    for i in range(5):\n",
        "        index = 1\n",
        "        while(index<=63):\n",
        "            colname = dfs[i].columns[index]\n",
        "            col = getattr(dfs[i], colname)\n",
        "            dfs[i][colname] = col.astype(float)\n",
        "            index+=1\n",
        "\n",
        "convert_columns_type_float(dataframes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz5yO-ZzIYtn"
      },
      "source": [
        "#### 2.B Convert the class label types to int\n",
        "If we look the class label `Y`, we notice that the values are shown either as `b'0'` or `b'1'`   \n",
        "They actually correspond to bankruptcy being false and true respectively.   \n",
        "It is convenient to convert them to binary integers 0 and 1 respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVGswjJyIYtn"
      },
      "outputs": [],
      "source": [
        "# The class labels for all the dataframes are originally in object type.\n",
        "# Convert them to int types\n",
        "def convert_class_label_type_int(dfs):\n",
        "    for i in range(len(dfs)):\n",
        "        col = getattr(dfs[i], 'Y')\n",
        "        dfs[i]['Y'] = col.astype(int)\n",
        "\n",
        "convert_class_label_type_int(dataframes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmGDH0nxIYtn"
      },
      "source": [
        "## 3. Data Analysis and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjFgGFulIYtn"
      },
      "source": [
        "### 3.A Missing Data Analysis\n",
        "Surely, there is missing data. Let us now see how much of it is missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zshFHmLIYto"
      },
      "outputs": [],
      "source": [
        "############################################################\n",
        "# Get Clean dataframes by dropping all the rows which have missing values\n",
        "def drop_nan_rows(dataframes, verbose=False):\n",
        "    clean_dataframes = [df.dropna(axis=0, how='any') for df in dataframes]\n",
        "    if verbose:\n",
        "        for i in range(len(dataframes)):\n",
        "            print(str(i+1)+'year:','Original Length=', len(dataframes[i]), '\\tCleaned Length=', len(clean_dataframes[i]), '\\tMissing Data=', len(dataframes[i])-len(clean_dataframes[i]))\n",
        "    return clean_dataframes\n",
        "\n",
        "# Doing a quick analysis of how many missing values are there in each of the 5 dataframes\n",
        "nan_dropped_dataframes = drop_nan_rows(dataframes, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VHfgkm9IYto"
      },
      "source": [
        "The above step shows us that there are a lot of rows in each of the 5 dataframes which have missing data in at least one of the features. In most of these dataframes, the missing-data-rows correspond to more than 50% of the entire data.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mG1mGrKIYto"
      },
      "source": [
        "#### 3.A.a Generate Sparsity Matrix for the missing data\n",
        "Now that we have established that there is a lot of missing data, let us find out if the missing data has some correlation.   \n",
        "The `matrix` function from the `missingno` library helps us generate sparsity matrix, which shows us the gaps in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrvOPXQTIYto"
      },
      "outputs": [],
      "source": [
        "# generate the sparsity matrix (figure) for all the dataframes\n",
        "def generate_sparsity_matrix(dfs):\n",
        "    for i in range(5):\n",
        "        missing_df_i = dfs[i].columns[dfs[i].isnull().any()].tolist()\n",
        "        msno.matrix(dfs[i][missing_df_i], figsize=(20,5))\n",
        "\n",
        "generate_sparsity_matrix(dataframes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-mOmfeoIYto"
      },
      "source": [
        "From the above plots of sparsity for all the 5 dataframes, we could notice a lot of sparsity for the feature `X37` has the highest sparsity among all the features for all the dataframes. The feature `X21` is sparse for some, if not all, dataframes. Also, more or less, all the features have missing data samples.   \n",
        "\n",
        "From the above sparsity-plot, we could only know how sparse the data is, yet we don't know if the data missing-ness is correlated among any features, i.e., is the data missing completely at random? Or are there any features that are missing together? as a next step, let us find out if there is some correlation among the features.\n",
        "\n",
        "However, by now it is clear that simply dropping all the rows with missing values, or eliminating all the features which have missing values is not a good approach of dealing with the missing data, as it leads to tremendous data loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHm4KxxlIYtp"
      },
      "source": [
        "#### 3.A.b Generate Heat Map for the missing data   \n",
        "Now, let us find out if there is some correlation among the missing features.    \n",
        "\n",
        "Using the `heatmap` function from `missingno` library, let us plot the heatmaps for all the dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfGVu6AIIYtp"
      },
      "outputs": [],
      "source": [
        "# generate the heatmap for all the dataframes\n",
        "def generate_heatmap(dfs):\n",
        "    for i in range(5):\n",
        "        missing_df_i = dfs[i].columns[dfs[i].isnull().any()].tolist()\n",
        "        msno.heatmap(dfs[i][missing_df_i], figsize=(20,20))\n",
        "\n",
        "generate_heatmap(dataframes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmbs1e4WIYtp"
      },
      "source": [
        "The heat maps above, for all the 5 dataframes, describe the degree of nullity relationship between different features.    The range of this nullity correlation is from -1 to 1 (-1 ≤ R ≤ 1).    \n",
        "Features with no missing value are excluded in the heatmap. If the nullity correlation is very close to zero (-0.05 < R < 0.05), no value will be displayed.    \n",
        "\n",
        "A perfect positive nullity correlation (R=1) indicates when the first feature and the second feature both have corresponding missing values.       \n",
        "\n",
        "A perfect negative nullity correlation (R=-1) means that one of the features is missing and the second is not missing.   \n",
        "\n",
        "The takeaway is that, in each dataframe, there are some features that are heavily correlated (R = 1 or -1) and also there are features that are not essentially correlated (R values close to 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5u_rYWNIYtp"
      },
      "source": [
        "### 3.B Data Imputation\n",
        "\n",
        "It is now established that we need to impute (fill in the gaps) the missing data, as dropping the missing rows or eliminating the missing features is not an option.   \n",
        "\n",
        "We would like to explore some of the widely used missing data imputation techniques.   \n",
        "<b>\n",
        "1. Mean Imputation (baseline method)\n",
        "2. k Nearest Neighbors (k-NN) Imputation\n",
        "3. Expectation-Maximization (EM) Imputation\n",
        "4. Multivariate Imputation using Chained Equations (MICE)\n",
        "</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pQbWlplIYtq"
      },
      "source": [
        "#### 3.B.a Mean Imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5c7NtwHIYtq"
      },
      "outputs": [],
      "source": [
        "def perform_mean_imputation(dfs):\n",
        "    # Construct an imputer with strategy as 'mean', to mean-impute along the columns\n",
        "    imputer = Imputer(missing_values=np.nan, strategy='mean', axis=0)\n",
        "    mean_imputed_dfs = [pd.DataFrame(imputer.fit_transform(df)) for df in dfs]\n",
        "    for i in range(len(dfs)):\n",
        "        mean_imputed_dfs[i].columns = dfs[i].columns\n",
        "    return mean_imputed_dfs\n",
        "\n",
        "mean_imputed_dataframes = perform_mean_imputation(dataframes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBH1drpAIYtq"
      },
      "source": [
        "#### 3.B.b k-Nearest Neighbors (k-NN) Imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T730s9dmIYtq"
      },
      "outputs": [],
      "source": [
        "def perform_knn_imputation(dfs):\n",
        "    knn_imputed_datasets = [fancyimpute.KNN(k=100,verbose=True).complete(dfs[i]) for i in range(len(dfs))]\n",
        "    return [pd.DataFrame(data=knn_imputed_datasets[i]) for i in range(len(dfs))]\n",
        "\n",
        "knn_imputed_dataframes = perform_knn_imputation(dataframes)\n",
        "set_new_headers(knn_imputed_dataframes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht8FLMwwIYtq"
      },
      "source": [
        "#### 3.B.c Expectation-Maximization (EM) Imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS5b5w0BIYtr"
      },
      "outputs": [],
      "source": [
        "def perform_EM_imputation(dfs):\n",
        "    em_imputed_datasets = [impy.imputations.cs.em(dfs[i].values, loops=50, dtype='cont') for i in range(len(dfs))]\n",
        "    return [pd.DataFrame(data=em_imputed_datasets[i]) for i in range(len(dfs))]\n",
        "\n",
        "em_imputed_dataframes = perform_EM_imputation(dataframes)\n",
        "set_new_headers(em_imputed_dataframes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry7nw93sIYtr"
      },
      "source": [
        "#### 3.B.d MICE imputation (Multivariate Imputation using Chained Equation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AxUxN3CIYtr"
      },
      "outputs": [],
      "source": [
        "# Obtaining the completed features for all the 5 dataframes by doing MICE (Multiple Imputation from Chained Equations)\n",
        "def perform_MICE_imputation(dfs):\n",
        "    mice_imputed_datasets = [fancyimpute.MICE(verbose=False).complete(dfs[i]) for i in range(len(dfs))]\n",
        "    return [pd.DataFrame(data=mice_imputed_datasets[i]) for i in range(len(dfs))]\n",
        "\n",
        "mice_imputed_dataframes = perform_MICE_imputation(dataframes)\n",
        "set_new_headers(mice_imputed_dataframes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmtd2P_YIYtr"
      },
      "source": [
        "In the above 4 steps, we have successfully created 4 differently imputed dataframes using: Mean, k-NN, EM and MICE techniques respectively.   \n",
        "\n",
        "Here below, we create a dictionary of all the imputed dataframes to re-use them in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3127guldIYtr"
      },
      "outputs": [],
      "source": [
        "imputed_dataframes_dictionary = OrderedDict()\n",
        "imputed_dataframes_dictionary['Mean'] = mean_imputed_dataframes\n",
        "imputed_dataframes_dictionary['k-NN'] = knn_imputed_dataframes\n",
        "imputed_dataframes_dictionary['EM'] = em_imputed_dataframes\n",
        "imputed_dataframes_dictionary['MICE'] = mice_imputed_dataframes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6IDQz9tIYtr"
      },
      "source": [
        "### ---------------------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM7PZwUFIYts"
      },
      "source": [
        "### 3.C Dealing with imbalanced data   \n",
        "\n",
        "In the steps seen above, we have successfully dealt with the missing data. But we have not dealt with the class imbalance (if any) in the data. Simply put, Data Imbalance is a condition where the samples belonging to one or more 'majority' class labels of a labelled dataset heavily outnumber the sample belonging to the other 'minority' classes.   \n",
        "\n",
        "Data imbalance critically affects the modeling as the models won't have sufficient data belonging to minority classes to train on and this leads to biased models, ultimately leading to poor performance on test data.   \n",
        "\n",
        "Firstly, let us see if our data is imbalanced, and to what extent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dX0qFurIYts"
      },
      "outputs": [],
      "source": [
        "def check_data_imbalance(dfs):\n",
        "    for i in range(len(dfs)):\n",
        "        print('Dataset: '+str(i+1)+'year')\n",
        "        print(dfs[i].groupby('Y').size())\n",
        "        minority_percent = (dfs[i]['Y'].tolist().count(1) / len(dfs[i]['Y'].tolist()))*100\n",
        "        print('Minority (label 1) percentage: '+  str(minority_percent) + '%')\n",
        "        print('-'*64)\n",
        "\n",
        "check_data_imbalance(dataframes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHUXVZhMIYts"
      },
      "source": [
        "We have seen in the step above that there is a lot of data imbalance for our datasets, as indicated by the percentage of minority class (label `1`) samples among their datasets. With this huge magnitude of data imbalance, the models will not train wel if we leave them as is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwRus8osIYts"
      },
      "source": [
        "#### 3.C.a Oversampling with SMOTE (Synthetic Minority Over Sampling Technique)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDXcv2u2IYts"
      },
      "outputs": [],
      "source": [
        "# Split the features and labels into separate dataframes for all the original dataframes\n",
        "def split_dataframes_features_labels(dfs):\n",
        "    feature_dfs = [dfs[i].iloc[:,0:64] for i in range(len(dfs))]\n",
        "    label_dfs = [dfs[i].iloc[:,64] for i in range(len(dfs))]\n",
        "    return feature_dfs, label_dfs\n",
        "\n",
        "# Performs the SMOTE oversampling fro given dataframes.\n",
        "def oversample_data_SMOTE(dfs, verbose=False):\n",
        "    smote = SMOTE(ratio='auto' , random_state=42, k_neighbors=10)\n",
        "    #Split the features and labels for each dataframe\n",
        "    feature_dfs, label_dfs = split_dataframes_features_labels(dfs)\n",
        "    resampled_feature_arrays = []\n",
        "    resampled_label_arrays = []\n",
        "    for i in range(len(dfs)):\n",
        "        if verbose: print('Dataset: ' + str(i+1) + 'year:')\n",
        "        if verbose: print('Original dataset shape {}'.format(Counter(label_dfs[i])))\n",
        "        dfi_features_res, dfi_label_res = smote.fit_sample(feature_dfs[i], label_dfs[i])\n",
        "        if verbose: print('Resampled dataset shape {}\\n'.format(Counter(dfi_label_res)))\n",
        "        # Append the resampled feature and label arrays of ith dataframe to their respective list of arrays\n",
        "        resampled_feature_arrays.append(dfi_features_res)\n",
        "        resampled_label_arrays.append(dfi_label_res)\n",
        "    return resampled_feature_arrays, resampled_label_arrays\n",
        "\n",
        "# Utility Function to convert the arrays of features and labels to pandas dataframes, and then join them.\n",
        "# Also re-assign the columns headers.\n",
        "def restructure_arrays_to_dataframes(feature_arrays, label_arrays):\n",
        "    resampled_dfs = []\n",
        "    for i in range(len(feature_arrays)):\n",
        "        feature_df = pd.DataFrame(data=feature_arrays[i])\n",
        "        label_df = pd.DataFrame(data=label_arrays[i])\n",
        "        # Must set the column header for label_df, otherwise it wont join with feature_df, as columns overlap (with col names '0')\n",
        "        label_df.columns=['Y']\n",
        "        resampled_dfs.append(feature_df.join(label_df))\n",
        "    # re-assign the column headers for features and labels\n",
        "    set_new_headers(resampled_dfs)\n",
        "    return resampled_dfs\n",
        "\n",
        "# Perform SMOTE oversampling on all the imputed dataframes, and return them in a dictionary.\n",
        "def perform_oversampling_on_imputed_dataframes(df_dict):\n",
        "    imputed_oversampled_dataframes_dictionary = OrderedDict()\n",
        "    for key,dfs in df_dict.items():\n",
        "        print('SMOTE Oversampling for ' + key + ' imputed dataframes\\n')\n",
        "        smote_feature_arrays, smote_label_arrays = oversample_data_SMOTE(dfs, verbose=True)\n",
        "        oversampled_dataframes = restructure_arrays_to_dataframes(smote_feature_arrays, smote_label_arrays)\n",
        "        imputed_oversampled_dataframes_dictionary[key] = oversampled_dataframes\n",
        "        print('-'*100)\n",
        "    return imputed_oversampled_dataframes_dictionary\n",
        "\n",
        "imputed_oversampled_dataframes_dictionary = perform_oversampling_on_imputed_dataframes(imputed_dataframes_dictionary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-cSK7ZiIYtt"
      },
      "source": [
        "## 4. Data Modeling: Building Classification Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWe36rHVIYtt"
      },
      "source": [
        "### 4.A K-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fI0PX-6IYtt"
      },
      "outputs": [],
      "source": [
        "def prepare_kfold_cv_data(k, X, y, verbose=False):\n",
        "    X = X.values\n",
        "    y = y.values\n",
        "    kf = KFold(n_splits=k, shuffle=False, random_state=42)\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    X_test = []\n",
        "    y_test = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train.append(X[train_index])\n",
        "        y_train.append(y[train_index])\n",
        "        X_test.append(X[test_index])\n",
        "        y_test.append(y[test_index])\n",
        "    return X_train, y_train, X_test, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDBWXTs7IYtu"
      },
      "source": [
        "### 4.B MODELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXy266ilIYtu"
      },
      "source": [
        "### 4.B.a Gaussian Naive Bayes classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1V31iRkIYtu"
      },
      "outputs": [],
      "source": [
        "# Gaussian Naive Bayes classifier\n",
        "gnb_classifier = GaussianNB()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmQ6kI4RIYtu"
      },
      "source": [
        "### 4.B.b Logistic Regression classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShFhj8zhIYtv"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression classifier\n",
        "lr_classifier = LogisticRegression(penalty = 'l1', random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Imi2ZUhKIYtv"
      },
      "source": [
        "### 4.B.c Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIRR49XpIYtv"
      },
      "outputs": [],
      "source": [
        "# Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5YSK4WBIYtv"
      },
      "source": [
        "### 4.B.d Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu6f_HFBIYtw"
      },
      "outputs": [],
      "source": [
        "# Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators = 5, criterion = 'entropy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZLwTbpeIYtw"
      },
      "source": [
        "### 4.B.e Extreme Gradient Boosting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4svrrV9QIYtw"
      },
      "outputs": [],
      "source": [
        "# eXtreme Gradient Boosting Classifier (XGBClassifier)\n",
        "xgb_classifier = XGBClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev9zARKoIYtw"
      },
      "source": [
        "### 4.B.f Balanced Bagging Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xt2HX1gHIYtw"
      },
      "outputs": [],
      "source": [
        "# Balanced Bagging Classifier\n",
        "bb_classifier = BalancedBaggingClassifier(base_estimator = RandomForestClassifier(criterion='entropy'), n_estimators = 5, bootstrap = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ce2fiPRNIYtx"
      },
      "outputs": [],
      "source": [
        "# creating a dictionary of models\n",
        "models_dictionary = OrderedDict()\n",
        "\n",
        "models_dictionary['Gaussian Naive Bayes'] = gnb_classifier\n",
        "models_dictionary['Logistic Regression'] = lr_classifier\n",
        "models_dictionary['Decision Tree'] = dt_classifier\n",
        "models_dictionary['Extreme Gradient Boosting'] = xgb_classifier\n",
        "models_dictionary['Random Forest'] = rf_classifier\n",
        "models_dictionary['Balanced Bagging'] = bb_classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-S8stTcIYtx"
      },
      "outputs": [],
      "source": [
        "# perform data modeling\n",
        "def perform_data_modeling(_models_, _imputers_, verbose=False, k_folds=5):\n",
        "\n",
        "    # 7 Models\n",
        "    # 4 Imputers\n",
        "    # 5 datasets (for 5 years)\n",
        "    # 7 metrics, averaged over all the K-Folds\n",
        "    model_results = OrderedDict()\n",
        "\n",
        "    # Iterate over the models\n",
        "    for model_name, clf in _models_.items():\n",
        "        if verbose: print(\"-\"*120, \"\\n\", \"Model: \" + '\\033[1m' + model_name + '\\033[0m' + \" Classifier\")\n",
        "        imputer_results = OrderedDict()\n",
        "\n",
        "        # Iterate over the different imputed_data mechanisms (Mean, k-NN, EM, MICE)\n",
        "        for imputer_name, dataframes_list in _imputers_.items():\n",
        "            if verbose: print('\\tImputer Technique: ' + '\\033[1m' + imputer_name + '\\033[0m')\n",
        "\n",
        "            # call the split_dataframes_features_labels function to get a list of features and labels for all the dataframes\n",
        "            feature_dfs, label_dfs = split_dataframes_features_labels(dataframes_list)\n",
        "\n",
        "            year_results = OrderedDict()\n",
        "\n",
        "            # Iterate over dataframe_list individually\n",
        "            for df_index in range(len(dataframes_list)):\n",
        "                if verbose: print('\\t\\tDataset: ' + '\\033[1m' + str(df_index+1) + 'year' + '\\033[0m')\n",
        "\n",
        "                # Calling the 'prepare_kfold_cv_data' returns lists of features and labels\n",
        "                # for train and test sets respectively.\n",
        "                # The number of items in the list is equal to k_folds\n",
        "                X_train_list, y_train_list, X_test_list, y_test_list = prepare_kfold_cv_data(k_folds, feature_dfs[df_index], label_dfs[df_index], verbose)\n",
        "\n",
        "                metrics_results = OrderedDict()\n",
        "                accuracy_list = np.zeros([k_folds])\n",
        "                precision_list = np.zeros([k_folds,2])\n",
        "                recall_list = np.zeros([k_folds,2])\n",
        "                TN_list = np.zeros([k_folds])\n",
        "                FP_list = np.zeros([k_folds])\n",
        "                FN_list = np.zeros([k_folds])\n",
        "                TP_list = np.zeros([k_folds])\n",
        "\n",
        "                # Iterate over all the k-folds\n",
        "                for k_index in range(k_folds):\n",
        "                    X_train = X_train_list[k_index]\n",
        "                    y_train = y_train_list[k_index]\n",
        "                    X_test = X_test_list[k_index]\n",
        "                    y_test = y_test_list[k_index]\n",
        "\n",
        "                    # Fit the model and\n",
        "                    clf = clf.fit(X_train, y_train)\n",
        "                    y_test_predicted = clf.predict(X_test)\n",
        "\n",
        "                    #code for calculating accuracy\n",
        "                    _accuracy_ = accuracy_score(y_test, y_test_predicted, normalize=True)\n",
        "                    accuracy_list[k_index] = _accuracy_\n",
        "\n",
        "                    #code for calculating recall\n",
        "                    _recalls_ = recall_score(y_test, y_test_predicted, average=None)\n",
        "                    recall_list[k_index] = _recalls_\n",
        "\n",
        "                    #code for calculating precision\n",
        "                    _precisions_ = precision_score(y_test, y_test_predicted, average=None)\n",
        "                    precision_list[k_index] = _precisions_\n",
        "\n",
        "                    #code for calculating confusion matrix\n",
        "                    _confusion_matrix_ = confusion_matrix(y_test, y_test_predicted)\n",
        "                    TN_list[k_index] = _confusion_matrix_[0][0]\n",
        "                    FP_list[k_index] = _confusion_matrix_[0][1]\n",
        "                    FN_list[k_index] = _confusion_matrix_[1][0]\n",
        "                    TP_list[k_index] = _confusion_matrix_[1][1]\n",
        "\n",
        "                # creating a metrics dictionary\n",
        "                metrics_results['Accuracy'] = np.mean(accuracy_list)\n",
        "                metrics_results['Precisions'] = np.mean(precision_list, axis=0)\n",
        "                metrics_results['Recalls'] = np.mean(recall_list, axis=0)\n",
        "                metrics_results['TN'] = np.mean(TN_list)\n",
        "                metrics_results['FP'] = np.mean(FP_list)\n",
        "                metrics_results['FN'] = np.mean(FN_list)\n",
        "                metrics_results['TP'] = np.mean(TP_list)\n",
        "\n",
        "                if verbose:\n",
        "                    print('\\t\\t\\tAccuracy:', metrics_results['Accuracy'])\n",
        "                    print('\\t\\t\\tPrecision:', metrics_results['Precisions'])\n",
        "                    print('\\t\\t\\tRecall:', metrics_results['Recalls'])\n",
        "\n",
        "                year_results[str(df_index+1)+'year'] = metrics_results\n",
        "\n",
        "            imputer_results[imputer_name] = year_results\n",
        "\n",
        "        model_results[model_name] = imputer_results\n",
        "\n",
        "    return model_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WV_FSLhYIYtx"
      },
      "outputs": [],
      "source": [
        "results = perform_data_modeling(models_dictionary, imputed_oversampled_dataframes_dictionary, verbose=True, k_folds=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCbrw4uGIYty"
      },
      "source": [
        "## Model Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7kqaHc5IYty"
      },
      "source": [
        "### Model Ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MR5HH1H8IYty"
      },
      "outputs": [],
      "source": [
        "# model -> imputer -> year\n",
        "def perform_model_ranking(models, imputers, results):\n",
        "    column_headers = ['-'] + list(imputers.keys())\n",
        "    rows = []\n",
        "    for model_name, model_details in results.items():\n",
        "        row = [model_name]\n",
        "        for imputer_name, imputer_details in model_details.items():\n",
        "            mean_accuracy = 0\n",
        "            for year, metrics in imputer_details.items():\n",
        "                mean_accuracy += metrics['Accuracy']\n",
        "            mean_accuracy = mean_accuracy/len(imputer_details)\n",
        "            row.append(mean_accuracy)\n",
        "        rows.append(row)\n",
        "    results_df = pd.DataFrame(data=rows, columns = column_headers)\n",
        "    return results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqpSpVGZIYty"
      },
      "outputs": [],
      "source": [
        "perform_model_ranking(models_dictionary, imputed_oversampled_dataframes_dictionary, results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vWPTSmgIYty"
      },
      "source": [
        "### Balanced Bagging: Effect of varying number of estimators on the accuracy scores on different datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZ6NAdDUIYtz"
      },
      "outputs": [],
      "source": [
        "# This list stores results of Balanced Bagging classifier obtained by running it for\n",
        "# various values of number of estimators in the range of 1 to 30\n",
        "results_by_estimators = []\n",
        "for i in range(29):\n",
        "    models_dictionary['Balanced Bagging'] = BalancedBaggingClassifier(base_estimator = RandomForestClassifier(criterion='entropy'), n_estimators = i+1, bootstrap = True)\n",
        "    results = perform_data_modeling(models_dictionary, imputed_oversampled_dataframes_dictionary, verbose=True, k_folds=5)\n",
        "    results_by_estimators.append(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJC6eOQ7IYtz"
      },
      "source": [
        "### Balanced Bagging: Plotting effect of number of estimators on Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6FH26G4IYtz"
      },
      "outputs": [],
      "source": [
        "year1_values = []\n",
        "year2_values = []\n",
        "year3_values = []\n",
        "year4_values = []\n",
        "year5_values = []\n",
        "\n",
        "# extract corresponding Balanced bagging with Mean imputation\n",
        "# classification metrics\n",
        "def extract_actual_values_from_dict(curr_dict):\n",
        "    temp_dict = curr_dict['Balanced Bagging']\n",
        "    return temp_dict['Mean']\n",
        "\n",
        "for i in range(29):\n",
        "    curr_dict = results_by_estimators[i]\n",
        "    curr_result = extract_actual_values_from_dict(curr_dict)\n",
        "\n",
        "\n",
        "    year_1_result = curr_result['1year']\n",
        "    year_2_result = curr_result['2year']\n",
        "    year_3_result = curr_result['3year']\n",
        "    year_4_result = curr_result['4year']\n",
        "    year_5_result = curr_result['5year']\n",
        "    year1_values.append(year_1_result['Accuracy'])\n",
        "    year2_values.append(year_2_result['Accuracy'])\n",
        "    year3_values.append(year_3_result['Accuracy'])\n",
        "    year4_values.append(year_4_result['Accuracy'])\n",
        "    year5_values.append(year_5_result['Accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIa8pwJzIYtz"
      },
      "source": [
        "### Plot of effect of number of estimators on Accuracy for Balanced Bagging classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8G2b-L-rIYtz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "estimators = [i+1 for i in range(29)]\n",
        "\n",
        "# plot year1, year2, year3, year4 and year5 accuracy values\n",
        "# for range of estimator values from 1 to 30\n",
        "plt.plot(estimators, year1_values, '.b-')\n",
        "plt.plot(estimators, year2_values, '.r-')\n",
        "plt.plot(estimators, year3_values, '.y-')\n",
        "plt.plot(estimators, year4_values, '.g-')\n",
        "plt.plot(estimators, year5_values, '.m-')\n",
        "plt.xlabel(\"\\nNumber of estimators\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"\\nEffect of varying number of estimators on the accuracy scores on different datasets\\n\")\n",
        "\n",
        "# display legend\n",
        "plt.plot(10, 0.93, '.b-', label='Year 1')\n",
        "plt.plot(10, 0.93, '.r-', label='Year 2')\n",
        "plt.plot(10, 0.93, '.y-', label='Year 3')\n",
        "plt.plot(10, 0.93, '.g-', label='Year 4')\n",
        "plt.plot(10, 0.93, '.m-', label='Year 5')\n",
        "\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvx3uvcbIYt0"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kZ738ovIYt0"
      },
      "source": [
        "https://docs.scipy.org/doc/numpy-1.14.0/reference/\n",
        "https://pandas.pydata.org/\n",
        "https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.arff.loadarff.html\n",
        "https://github.com/iskandr/fancyimpute\n",
        "https://pypi.org/project/impyute/\n",
        "http://scikit-learn.org/stable/modules/preprocessing.html\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "https://docs.python.org/3/library/collections.html\n",
        "http://xgboost.readthedocs.io/en/latest/python/python_api.html\n",
        "http://scikit-learn.org/stable/modules/svm.html\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "http://contrib.scikit-learn.org/imbalanced-learn/stable/generated/imblearn.ensemble.BalancedBaggingClassifier.html\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
        "https://docs.python.org/2/library/random.html\n",
        "http://scikit-learn.org/stable/modules/classes.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rIBLbr_IYt0"
      },
      "source": [
        "## End of Project"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}